{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyM76EAHZnGtI5jTnfp5K6pO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## 합성곱 신경망 소개\n","\n","혼공 p437 참조\n","\n","\n","합성곱 신경망(Convolutional Neural Networks, CNN)은 이미지나 비디오 등의 공간적 구조를 가진 데이터를 처리하는 데 유용한 딥러닝 모델\n","\n","- 입력 레이어: 원시 이미지 데이터를 받아들이는 첫 번째 레이어. 이미지는 보통 높이, 너비, 그리고 색상 채널(예: RGB)의 3차원 텐서로 표현.\n","\n","- 합성곱 레이어(Convolutional Layer): 이 레이어는 이미지의 지역적 특성을 학습. 이 레이어에서는 \"필터\" 또는 \"커널\"이라는 작은 윈도우가 이미지를 스캔하며 이동. 각 필터는 고유한 특징(예: 가장자리, 텍스처 등)을 인식.\n","\n","- 필터/커널: 합성곱 층에서 사용되는 작은 행렬로, 랜덤한 값으로 초기화된 후에 데이터를 통해 학습. 필터는 이미지의 여러 부분을 스캔하며 특정 특징을 인식.\n","\n","- 스트라이드: 필터가 이미지 위를 이동하는 간격. 스트라이드 값에 따라 출력 피쳐 맵의 크기가 결정되며 큰 스트라이드는 작은 출력 차원을 생성하고, 작은 스트라이드는 큰 출력 차원을 생성.(디폴트 값은 1)\n","\n","- 패딩: 입력 이미지의 주위에 픽셀을 추가하는 방법으로, 합성곱이 적용된 후의 출력 크기를 조절할 수 있다. 패딩이 없으면 합성곱 연산을 거치면서 출력 이미지의 크기가 작아진다. 패딩을 사용하면 이를 방지하고 원본 이미지의 공간적 크기를 보존할 수 있다."],"metadata":{"id":"tD6W5Q5L8T4y"}},{"cell_type":"markdown","source":["- 활성화 함수: 일반적으로 ReLU(Rectified Linear Unit) 같은 비선형 활성화 함수가 사용되어 복잡한 패턴을 학습할 수 있도록 한다.\n","\n","- 풀링 레이어(Pooling Layer): 이 레이어는 출력을 다운샘플링하여 모델의 복잡도를 줄이고, 과적합을 방지하며, 일부 공간적 인식력을 보존. 가장 많이 사용되는 풀링 방법은 최대 풀링(Max Pooling)이다.\n","\n","- 완전 연결 레이어(Fully Connected Layer): 이 레이어는 모든 입력 뉴런이 모든 출력 뉴런과 연결되어 있다. 이는 일반적으로 신경망의 마지막 단계에서 사용되며, 합성곱 및 풀링 레이어를 통해 학습된 고차원 특징을 이용하여 최종적으로 분류나 회귀 등의 작업을 수행.\n","\n","- 이러한 각 요소들이 어떻게 함께 작동하는지 간단하게 설명하면, 합성곱 레이어의 필터는 입력 이미지를 스캔하면서 지역적인 특징을 감지하고, 이 정보를 활성화 맵(특징 맵)의 형태로 출력. 이때, 스트라이드와 패딩은 필터가 이미지를 어떻게 스캔할지를 결정하며, 활성화 함수는 비선형성을 추가하여 복잡한 패턴을 학습하게 해준다. 그 다음, 풀링 레이어는 이 특징 맵을 다운샘플링하여 모델의 복잡도를 줄이고, 공간적 인식력을 보존하며, 과적합을 방지한다. 마지막으로, 완전 연결 레이어는 이런 모든 특징들을 종합하여 최종적으로 이미지의 클래스를 예측하거나, 객체의 위치를 회귀하는 등의 작업을 수행한다.\n","이런 식으로, CNN은 각 레이어에서 이미지의 다양한 특징을 학습하고, 이 정보를 바탕으로 복잡한 패턴을 인식하고, 효과적인 예측을 수행하게 됩니다."],"metadata":{"id":"vuzMntf38qhB"}},{"cell_type":"markdown","source":["- 2D 합성곱 (Conv2D): 이는 가장 흔히 사용되는 합성곱 유형으로, 이미지 같은 2차원 데이터에 적용. Conv2D는 입력 데이터의 지역적 특징을 인식하고 이를 학습하는 데 사용.\n","\n","- 1D 합성곱 (Conv1D): 이 유형의 합성곱은 시퀀스 데이터(예: 시계열 데이터, 텍스트 데이터)를 처리하는 데 주로 사용. 이는 입력 시퀀스의 연속적인 부분을 고려하므로, 특히 시간적인 순서 정보가 중요한 문제에 유용."],"metadata":{"id":"ON7VmDGH8qpt"}},{"cell_type":"markdown","source":["CNN(Convolutional Neural Network):\n","컨볼루션 연산을 통해 이미지 특징을 추출하고, 풀링 연산으로 공간적인 크기를 줄임 객체 감지 및 이미지 분류 작업에 뛰어난 성능\n","\n","- 합성곱 레이어 추가: 32개의 필터, 필터(커널) 사이즈 5x5 픽셀,\n","- 스트라이드 1x1(필터가 한번에 얼마나 이동할지)\n","-  패딩 same: 합성곱연산으로 출력 이미지 크기가 작아지면 남는 부분에 픽셀 채움\n","-  필터 수 -> 많을수록 더 다양한 특징 학습\n","model.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1), padding='same', activation='relu', input_shape=input_shape))\n","\n","-  풀링 레이어 추가(입력 크기를 절반으로 줄여주는 역할), 풀링윈도우(필터) 사이즈 2x2\n","-  윈도우 내의 값 중 최대값을 선택해 출력 -> 작은 특징들이 손실될 위험성o\n","model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","\n","-  드롭아웃 레이어 추가(25% 확률로 입력 유닛을 무작위 제외 -> 과적합 방지)\n","-  에포크 한 번 돌때마다 새롭게 무작위 추출\n","model.add(Dropout(0.25))\n","\n","-  플래튼 레이어 추가(다차원 입력을 일차원으로 펼침)\n","-  합성곱/풀링 레이어 이후엔 다차원 텐서 데이터가 생성됨 -> Dense레이어 전에 플래튼 레이어로 펼쳐줌\n","model.add(Flatten())\n","\n","-  연결 레이어 추가, 1000개 유닛(Dense = Fully Connected 레이어)\n","model.add(Dense(1000, activation='relu'))"],"metadata":{"id":"ELwvDY8c8qtN"}},{"cell_type":"markdown","source":["간단한 컨브넷 만들기"],"metadata":{"id":"fbe-8Q_L8qxN"}},{"cell_type":"code","source":["from tensorflow import keras\n","from tensorflow.keras import layers\n","inputs = keras.Input(shape=(28, 28, 1)) # (28, 28, 1) 형태의 3차원 텐서를 입력\n","x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n","# 32개의 3x3크기의 필터를 사용하는 합성곱 레이어를 정의하고, 입력 이미지에 적용\n","x = layers.MaxPooling2D(pool_size=2)(x)\n","x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n","x = layers.MaxPooling2D(pool_size=2)(x)\n","x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n","x = layers.Flatten()(x) # 텐서를 1차원으로 평탄화해서 모든 픽셀 값들을 연속적인 벡터 형태로 변환\n","# 출력 레이어로 완전 연결 레이어로 10개의 뉴런을 가지며 각 뉴런은 이미지가 특정 클래스에 속할 확률을 출력\n","outputs = layers.Dense(10, activation=\"softmax\")(x)\n","model = keras.Model(inputs=inputs, outputs=outputs)"],"metadata":{"id":"08THX7vo8q0k","executionInfo":{"status":"ok","timestamp":1688696986022,"user_tz":-540,"elapsed":5511,"user":{"displayName":"일땽","userId":"01657347254653910294"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["모델의 Summary() 메서드 출력"],"metadata":{"id":"MUt9VZ1A8q39"}},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TEvT5N9H8q71","executionInfo":{"status":"ok","timestamp":1688696986025,"user_tz":-540,"elapsed":39,"user":{"displayName":"일땽","userId":"01657347254653910294"}},"outputId":"55895f8a-571b-4027-9de5-073f2aa638e2"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n","                                                                 \n"," conv2d (Conv2D)             (None, 26, 26, 32)        320       \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n"," )                                                               \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 3, 3, 128)         73856     \n","                                                                 \n"," flatten (Flatten)           (None, 1152)              0         \n","                                                                 \n"," dense (Dense)               (None, 10)                11530     \n","                                                                 \n","=================================================================\n","Total params: 104,202\n","Trainable params: 104,202\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["MNIST 이미지에서 컨브넷 훈련하기"],"metadata":{"id":"Xzqdbb0H8rB2"}},{"cell_type":"code","source":["from tensorflow.keras.datasets import mnist\n","\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n","train_images = train_images.reshape((60000, 28, 28, 1)) # = 흑백이미지\n","train_images = train_images.astype(\"float32\") / 255 #정규화 과정 1\n","test_images = test_images.reshape((10000, 28, 28, 1))\n","test_images = test_images.astype(\"float32\") / 255 #정규화 2\n","model.compile(optimizer=\"rmsprop\",\n","    loss=\"sparse_categorical_crossentropy\",# 정수형으로 값만 출력되게 함.\n","    metrics=[\"accuracy\"])\n","model.fit(train_images, train_labels, epochs=5, batch_size=64) #6만개를 64개의 묶음으로 = 약 948개"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yb9WgvoC8rF9","executionInfo":{"status":"ok","timestamp":1688697300673,"user_tz":-540,"elapsed":45231,"user":{"displayName":"일땽","userId":"01657347254653910294"}},"outputId":"55d3aba6-fbc8-4103-ac45-1b4f7f95f9c3"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 2s 0us/step\n","Epoch 1/5\n","938/938 [==============================] - 14s 3ms/step - loss: 0.1611 - accuracy: 0.9499\n","Epoch 2/5\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0452 - accuracy: 0.9861\n","Epoch 3/5\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0311 - accuracy: 0.9902\n","Epoch 4/5\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0233 - accuracy: 0.9927\n","Epoch 5/5\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0177 - accuracy: 0.9944\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fe1913a5a80>"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["컨브넷 평가하기"],"metadata":{"id":"W9Yc0DgC8rJ1"}},{"cell_type":"code","source":["test_loss,test_acc = model.evaluate(test_images, test_labels)\n","print(f\"테스트 정확도: {test_acc:3f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L_gfCO-P8rNu","executionInfo":{"status":"ok","timestamp":1688697500427,"user_tz":-540,"elapsed":2295,"user":{"displayName":"일땽","userId":"01657347254653910294"}},"outputId":"af6b9708-564a-49bc-8069-2cabc1b1efe9"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 1s 3ms/step - loss: 0.0244 - accuracy: 0.9925\n","테스트 정확도: 0.992500\n"]}]}]}